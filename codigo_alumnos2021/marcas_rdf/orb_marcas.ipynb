{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/dani/Escritorio/proyectos/Python/clase/robotica/Robotica/codigo_alumnos2021/marcas_rdf'"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "import Percepcion as p\n",
    "perceptor = p.Percepcion()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "flechas = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/Flecha2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha10.png')))[1],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "man = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/man-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-10.png')))[1],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "stairs = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/stairs-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-10.png')))[1],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "telephone = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/telephone-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-10.png')))[1],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "woman = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/woman-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-10.png')))[1],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('uint8')"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flechas[0].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "def compute(img):\n",
    "\timg = cv2.cvtColor(img.copy(), cv2.COLOR_RGBA2GRAY)\n",
    "\timg = img - 255\n",
    "\n",
    "\tcont_list_im, hier = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\t# cont_list_im = np.array(cont_list_im)\n",
    "\t# cont_list_im = cont_list_im[np.array([cv2.contourArea(conto) for conto in cont_list_im]) > 10]\n",
    "\torb = cv2.ORB_create()\n",
    "\tellip = cv2.fitEllipse(cont_list_im[0])\n",
    "\tcen, ejes, angulo = np.array(ellip[0]), np.array(ellip[1]), ellip[2]\n",
    "\tkp = cv2.KeyPoint(cen[0], cen[1], np.mean(ejes) * 1.3, angulo - 90)\n",
    "\tlkp, des = orb.compute(img, [kp])\n",
    "\treturn des"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "\n",
    "flechas_orb = []\n",
    "for img in flechas:\n",
    "\ttry:\n",
    "\t\tc = compute(img)\n",
    "\t\tif c is not None:\n",
    "\t\t\tflechas_orb.append(c)\n",
    "\texcept:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "man_orb = []\n",
    "for img in man:\n",
    "\ttry:\n",
    "\t\tc = compute(img)\n",
    "\t\tif c is not None:\n",
    "\t\t\tman_orb.append(c)\n",
    "\texcept:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "woman_orb = []\n",
    "for img in woman:\n",
    "\ttry:\n",
    "\t\tc = compute(img)\n",
    "\t\tif c is not None:\n",
    "\t\t\twoman_orb.append(c)\n",
    "\texcept:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "telephone_orb = []\n",
    "for img in telephone:\n",
    "\ttry:\n",
    "\t\tc = compute(img)\n",
    "\t\tif c is not None:\n",
    "\t\t\ttelephone_orb.append(c)\n",
    "\texcept:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "stairs_orb = []\n",
    "for img in stairs:\n",
    "\ttry:\n",
    "\t\tc = compute(img)\n",
    "\t\tif c is not None:\n",
    "\t\t\tstairs_orb.append(c)\n",
    "\texcept:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "def hammingDist(d1, d2):\n",
    "\tassert d1.dtype == np.uint8 and d2.dtype == np.uint8\n",
    "\td1_bits = np.unpackbits(d1)\n",
    "\td2_bits = np.unpackbits(d2)\n",
    "\treturn np.bitwise_xor(d1_bits, d2_bits).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_ref_images():\n",
    "\twoman = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/woman-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/woman-10.png')))[1],\n",
    "\t]\n",
    "\n",
    "\ttelephone = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/telephone-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/telephone-10.png')))[1],\n",
    "\t]\n",
    "\n",
    "\tstairs = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/stairs-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-10.png')))[1],\n",
    "\t]\n",
    "\n",
    "\tman = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/man-2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/man-10.png')))[1],\n",
    "\t]\n",
    "\n",
    "\tflechas = [\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha1.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread('marcas-capturasStage/Flecha2.png'))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha3.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha4.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha5.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha6.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha7.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha8.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha9.png')))[1],\n",
    "\tperceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha10.png')))[1],\n",
    "\t]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "def load_reference_descriptors():\n",
    "\tflechas_orb = []\n",
    "\tfor img in flechas:\n",
    "\t\ttry:\n",
    "\t\t\tc = compute(img)\n",
    "\t\t\tif c is not None:\n",
    "\t\t\t\tflechas_orb.append(c)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tman_orb = []\n",
    "\tfor img in man:\n",
    "\t\ttry:\n",
    "\t\t\tc = compute(img)\n",
    "\t\t\tif c is not None:\n",
    "\t\t\t\tman_orb.append(c)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\ttelephone_orb = []\n",
    "\tfor img in telephone:\n",
    "\t\ttry:\n",
    "\t\t\tc = compute(img)\n",
    "\t\t\tif c is not None:\n",
    "\t\t\t\ttelephone_orb.append(c)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\twoman_orb = []\n",
    "\tfor img in woman:\n",
    "\t\ttry:\n",
    "\t\t\tc = compute(img)\n",
    "\t\t\tif c is not None:\n",
    "\t\t\t\twoman_orb.append(c)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tstairs_orb = []\n",
    "\tfor img in stairs:\n",
    "\t\ttry:\n",
    "\t\t\tc = compute(img)\n",
    "\t\t\tif c is not None:\n",
    "\t\t\t\tstairs_orb.append(c)\n",
    "\t\texcept:\n",
    "\t\t\tpass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "def predict(pred):\n",
    "\tdist = []\n",
    "\tfor flecha in flechas_orb:\n",
    "\t\tdist.append(hammingDist(flecha, compute(pred)))\n",
    "\tdist2 = []\n",
    "\tfor man in man_orb:\n",
    "\t\tdist2.append(hammingDist(man, compute(pred)))\n",
    "\tdist3 = []\n",
    "\tfor woman in woman_orb:\n",
    "\t\tdist3.append(hammingDist(woman, compute(pred)))\n",
    "\tdist4 = []\n",
    "\tfor stair in stairs_orb:\n",
    "\t\tdist4.append(hammingDist(stair, compute(pred)))\n",
    "\tdist5 = []\n",
    "\tfor telephone in telephone_orb:\n",
    "\t\tdist5.append(hammingDist(telephone, compute(pred)))\n",
    "\tmean1 = np.mean(dist)\n",
    "\tmean2 = np.mean(dist2)\n",
    "\tmean3 = np.mean(dist3)\n",
    "\tmean4 = np.mean(dist4)\n",
    "\tmean5 = np.mean(dist5)\n",
    "\n",
    "\tif mean1 < mean2 and mean1 < mean3 and mean1 < mean4 and mean1 < mean5:\n",
    "\t\treturn 'flecha'\n",
    "\telif mean2 < mean1 and mean2 < mean3 and mean2 < mean4 and mean2 < mean5:\n",
    "\t\treturn 'man'\n",
    "\telif mean3 < mean1 and mean3 < mean2 and mean3 < mean4 and mean3 < mean5:\n",
    "\t\treturn 'woman'\n",
    "\telif mean4 < mean1 and mean4 < mean2 and mean4 < mean3 and mean4 < mean5:\n",
    "\t\treturn 'stairs'\n",
    "\telif mean5 < mean1 and mean5 < mean2 and mean5 < mean3 and mean5 < mean4:\n",
    "\t\treturn 'telephone'\n",
    "\treturn 'nothing'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "'flecha'"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(perceptor.procesarimagen(cv2.imread(('marcas-capturasStage/Flecha13.png')))[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "pred = perceptor.procesarimagen(cv2.imread(('marcas-capturasStage/stairs-11.png')))[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "dist = []\n",
    "for flecha in flechas_orb:\n",
    "\tdist.append(hammingDist(flecha, compute(pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "dist2 = []\n",
    "for man in man_orb:\n",
    "\tdist2.append(hammingDist(man, compute(pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "dist3 = []\n",
    "for woman in woman_orb:\n",
    "\tdist3.append(hammingDist(woman, compute(pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "(83.33333333333333, 46.22222222222222, 22.0)"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dist), np.mean(dist2),  np.mean(dist3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_flechas = pd.DataFrame(data=[np.unpackbits(x) for x in flechas_orb])\n",
    "df_flechas['label'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_man = pd.DataFrame(data=[np.unpackbits(x) for x in man_orb])\n",
    "df_man['label'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_man.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df = pd.concat([df_flechas, df_man], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "   0      1      2      3      4      5      6      7      8      9      ...  \\\n0      0      0      1      0      0      0      1      1      1      1  ...   \n1      0      0      1      0      0      0      0      0      1      1  ...   \n2      0      0      1      1      0      0      0      0      0      0  ...   \n3      0      0      0      0      0      0      0      0      0      0  ...   \n4      0      0      1      0      0      0      0      0      0      0  ...   \n5      0      0      0      0      0      0      1      0      1      0  ...   \n6      0      0      1      0      0      0      1      0      1      1  ...   \n7      0      0      1      0      0      0      0      0      0      0  ...   \n8      0      0      1      0      0      0      1      0      0      0  ...   \n9      0      0      1      0      0      0      0      0      0      0  ...   \n0      0      0      0      0      0      0      0      0      0      0  ...   \n1      0      0      0      0      0      0      0      0      0      0  ...   \n\n   98294  98295  98296  98297  98298  98299  98300  98301  98302  98303  \n0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n1    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n3    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n4    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n5    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n6    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n7    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n8    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n9    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n1    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n\n[12 rows x 98305 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>98294</th>\n      <th>98295</th>\n      <th>98296</th>\n      <th>98297</th>\n      <th>98298</th>\n      <th>98299</th>\n      <th>98300</th>\n      <th>98301</th>\n      <th>98302</th>\n      <th>98303</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows Ã— 98305 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "print(\"hola\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}